#!/usr/bin/env python3
"""
EXPLAIN ANALYZE å®Ÿè·µæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰
åŠ‡çš„ãªå·®ãŒå‡ºã‚‹ã‚¯ã‚¨ãƒªãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­è¨ˆã‚’æ¤œè¨¼
"""

import mysql.connector
import time
import re
from datetime import datetime
import json
import pandas as pd

DB_CONFIG = {
    'host': 'localhost',
    'port': 3366,
    'user': 'testuser',
    'password': 'testpass',
    'database': 'explain_test',
    'charset': 'utf8mb4'
}

class ImprovedBenchmark:
    def __init__(self):
        self.conn = mysql.connector.connect(**DB_CONFIG)
        self.results = []
        
    def __del__(self):
        if hasattr(self, 'conn'):
            self.conn.close()
    
    def extract_execution_time(self, explain_output):
        """EXPLAIN ANALYZEã®å‡ºåŠ›ã‹ã‚‰å®Ÿè¡Œæ™‚é–“ã‚’æŠ½å‡º"""
        if not explain_output:
            return None
            
        pattern = r'actual time=[\d.]+\.\.(\d+\.?\d*)'
        matches = re.findall(pattern, explain_output)
        
        if matches:
            return float(matches[-1])
        return None
    
    def extract_rows_examined(self, explain_output):
        """æ¤œæŸ»ã•ã‚ŒãŸè¡Œæ•°ã‚’æŠ½å‡º"""
        if not explain_output:
            return None
            
        pattern = r'rows=(\d+)'
        matches = re.findall(pattern, explain_output)
        
        if matches:
            return int(matches[0])
        return None
    
    def run_explain_analyze(self, query, description=""):
        """EXPLAIN ANALYZEã‚’å®Ÿè¡Œ"""
        cursor = self.conn.cursor()
        
        try:
            explain_query = f"EXPLAIN ANALYZE {query}"
            start_time = time.time()
            cursor.execute(explain_query)
            result = cursor.fetchall()
            end_time = time.time()
            
            explain_output = ""
            if result:
                explain_output = "\n".join([str(row[0]) for row in result])
            
            execution_time = self.extract_execution_time(explain_output)
            rows_examined = self.extract_rows_examined(explain_output)
            
            return {
                'description': description,
                'query': query.strip(),
                'execution_time_ms': execution_time,
                'rows_examined': rows_examined,
                'explain_output': explain_output,
                'total_time_sec': end_time - start_time,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'description': description,
                'query': query.strip(),
                'execution_time_ms': None,
                'rows_examined': None,
                'explain_output': f"ERROR: {str(e)}",
                'total_time_sec': None,
                'timestamp': datetime.now().isoformat()
            }
        finally:
            cursor.close()
    
    def create_index(self, index_name, table, columns, description=""):
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ"""
        cursor = self.conn.cursor()
        try:
            query = f"CREATE INDEX {index_name} ON {table}({columns})"
            print(f"ğŸ”§ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ: {description}")
            print(f"   SQL: {query}")
            start_time = time.time()
            cursor.execute(query)
            self.conn.commit()
            end_time = time.time()
            print(f"   âœ… ä½œæˆå®Œäº† ({end_time - start_time:.2f}ç§’)")
        except Exception as e:
            print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            cursor.close()
    
    def drop_all_indexes(self):
        """å…¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤"""
        cursor = self.conn.cursor()
        indexes_to_drop = [
            ('orders', 'idx_date_country'),
            ('orders', 'idx_country_date'),
            ('orders', 'idx_status_date'),
            ('orders', 'idx_amount_date'),
            ('orders', 'idx_covering'),
            ('orders', 'idx_optimal'),
            ('customers', 'idx_customer_country'),
            ('customers', 'idx_customer_reg_country')
        ]
        
        for table, index_name in indexes_to_drop:
            try:
                cursor.execute(f"DROP INDEX {index_name} ON {table}")
                self.conn.commit()
            except:
                pass
        cursor.close()
        print("ğŸ§¹ å…¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‰Šé™¤å®Œäº†")
    
    def get_heavy_queries(self):
        """é‡ã„ã‚¯ã‚¨ãƒªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®šç¾©"""
        return [
            {
                'name': 'hell_join_aggregation',
                'query': """
                SELECT c.country, c.city, 
                       COUNT(*) as order_count,
                       SUM(o.total_amount) as total_revenue,
                       AVG(o.total_amount) as avg_order_value,
                       MAX(o.total_amount) as max_order
                FROM customers c 
                JOIN orders o ON c.customer_id = o.customer_id
                WHERE o.order_date BETWEEN '2023-06-01' AND '2023-06-30'
                  AND o.total_amount > 500
                  AND c.registration_date < '2023-01-01'
                GROUP BY c.country, c.city
                HAVING COUNT(*) > 5
                ORDER BY total_revenue DESC
                LIMIT 50
                """,
                'description': 'ğŸ’€ åœ°ç„ã®çµåˆé›†è¨ˆã‚¯ã‚¨ãƒª'
            },
            {
                'name': 'subquery_nightmare',
                'query': """
                SELECT DISTINCT c.email, c.country,
                       (SELECT COUNT(*) FROM orders o2 
                        WHERE o2.customer_id = c.customer_id 
                          AND o2.status = 'delivered') as delivered_count,
                       (SELECT MAX(total_amount) FROM orders o3 
                        WHERE o3.customer_id = c.customer_id) as max_amount
                FROM customers c
                WHERE EXISTS (
                    SELECT 1 FROM orders o4 
                    WHERE o4.customer_id = c.customer_id 
                      AND o4.order_date >= '2023-01-01'
                      AND o4.total_amount > 800
                )
                ORDER BY max_amount DESC
                LIMIT 100
                """,
                'description': 'ğŸ‘» ã‚µãƒ–ã‚¯ã‚¨ãƒªåœ°ç„'
            },
            {
                'name': 'complex_date_range',
                'query': """
                SELECT DATE_FORMAT(o.order_date, '%Y-%m') as month,
                       o.shipping_country,
                       o.status,
                       COUNT(*) as order_count,
                       SUM(o.total_amount) as revenue,
                       COUNT(DISTINCT o.customer_id) as unique_customers
                FROM orders o
                WHERE o.order_date BETWEEN '2023-01-01' AND '2023-12-31'
                  AND o.total_amount BETWEEN 100 AND 2000
                  AND o.status IN ('delivered', 'shipped')
                GROUP BY DATE_FORMAT(o.order_date, '%Y-%m'), o.shipping_country, o.status
                ORDER BY month, revenue DESC
                """,
                'description': 'ğŸ“… è¤‡é›‘ãªæ—¥ä»˜ç¯„å›²é›†è¨ˆ'
            },
            {
                'name': 'ranking_with_window',
                'query': """
                SELECT c.country,
                       c.email,
                       o.total_amount,
                       o.order_date,
                       ROW_NUMBER() OVER (PARTITION BY c.country ORDER BY o.total_amount DESC) as rank_in_country
                FROM customers c
                JOIN orders o ON c.customer_id = o.customer_id
                WHERE o.order_date >= '2023-01-01'
                  AND o.status = 'delivered'
                HAVING rank_in_country <= 10
                ORDER BY c.country, rank_in_country
                """,
                'description': 'ğŸ† ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é–¢æ•°ãƒ©ãƒ³ã‚­ãƒ³ã‚°'
            }
        ]
    
    def get_index_strategies(self):
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æˆ¦ç•¥ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®šç¾©"""
        return [
            {
                'name': 'no_index',
                'description': 'âŒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãªã—',
                'setup': lambda: None,
                'cleanup': lambda: None
            },
            {
                'name': 'single_indexes',
                'description': 'ğŸ”¸ å˜ä¸€ã‚«ãƒ©ãƒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹',
                'setup': lambda: [
                    self.create_index('idx_order_date', 'orders', 'order_date', 'æ³¨æ–‡æ—¥'),
                    self.create_index('idx_country', 'orders', 'shipping_country', 'é…é€å›½'),
                    self.create_index('idx_status', 'orders', 'status', 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹')
                ],
                'cleanup': lambda: self.drop_all_indexes()
            },
            {
                'name': 'bad_composite',
                'description': 'ğŸ’© æ‚ªã„è¤‡åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆé€†é †ï¼‰',
                'setup': lambda: self.create_index('idx_bad_order', 'orders', 'shipping_country, status, order_date', 'æ‚ªã„é †åº'),
                'cleanup': lambda: self.drop_all_indexes()
            },
            {
                'name': 'good_composite',
                'description': 'âœ¨ è‰¯ã„è¤‡åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹',
                'setup': lambda: [
                    self.create_index('idx_optimal_1', 'orders', 'order_date, total_amount, status', 'æ—¥ä»˜â†’é‡‘é¡â†’ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'),
                    self.create_index('idx_customer_reg', 'customers', 'registration_date, country', 'ç™»éŒ²æ—¥â†’å›½')
                ],
                'cleanup': lambda: self.drop_all_indexes()
            },
            {
                'name': 'covering_index',
                'description': 'ğŸš€ ã‚«ãƒãƒªãƒ³ã‚°ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹',
                'setup': lambda: [
                    self.create_index('idx_covering', 'orders', 'order_date, shipping_country, status, total_amount, customer_id', 'ã‚«ãƒãƒªãƒ³ã‚°'),
                    self.create_index('idx_customer_all', 'customers', 'customer_id, country, city, email, registration_date', 'é¡§å®¢ã‚«ãƒãƒªãƒ³ã‚°')
                ],
                'cleanup': lambda: self.drop_all_indexes()
            }
        ]
    
    def run_benchmark_suite(self):
        """æ”¹è‰¯ç‰ˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
        print("ğŸ”¥ EXPLAIN ANALYZE å®Ÿè·µæ¤œè¨¼é–‹å§‹")
        print("=" * 80)
        
        queries = self.get_heavy_queries()
        strategies = self.get_index_strategies()
        
        for strategy in strategies:
            print(f"\n{strategy['description']}")
            print("-" * 70)
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­å®š
            if strategy['setup']:
                setup_result = strategy['setup']()
                if isinstance(setup_result, list):
                    pass  # è¤‡æ•°ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆæ¸ˆã¿
            
            # å„ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œ
            for query in queries:
                print(f"\n{query['description']}:")
                result = self.run_explain_analyze(query['query'], 
                                                f"{strategy['name']}_{query['name']}")
                
                result['strategy_name'] = strategy['name']
                result['strategy_description'] = strategy['description']
                result['query_name'] = query['name']
                result['query_description'] = query['description']
                
                self.results.append(result)
                
                if result['execution_time_ms']:
                    print(f"  â±ï¸  å®Ÿè¡Œæ™‚é–“: {result['execution_time_ms']:.1f}ms")
                    print(f"  ğŸ“Š æ¤œæŸ»è¡Œæ•°: {result['rows_examined']:,}è¡Œ" if result['rows_examined'] else "  ğŸ“Š æ¤œæŸ»è¡Œæ•°: N/A")
                    if result['total_time_sec']:
                        print(f"  ğŸ• ç·å®Ÿè¡Œæ™‚é–“: {result['total_time_sec']:.2f}ç§’")
                else:
                    print(f"  âŒ ã‚¨ãƒ©ãƒ¼: å®Ÿè¡Œå¤±æ•—")
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‰Šé™¤
            if strategy['cleanup']:
                strategy['cleanup']()
    
    def generate_impact_report(self):
        """ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã®å¼·ã„ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        if not self.results:
            print("âŒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        print("\n" + "ğŸ¯" * 30)
        print("ğŸ’¥ åŠ‡çš„æ”¹å–„åŠ¹æœãƒ¬ãƒãƒ¼ãƒˆ")
        print("ğŸ¯" * 30)
        
        df = pd.DataFrame(self.results)
        
        for query_name in df['query_name'].unique():
            query_results = df[df['query_name'] == query_name].copy()
            query_results = query_results.dropna(subset=['execution_time_ms'])
            query_results = query_results.sort_values('execution_time_ms')
            
            if len(query_results) == 0:
                continue
                
            print(f"\nğŸ”¥ {query_results.iloc[0]['query_description']}")
            print("-" * 60)
            
            baseline_time = None
            fastest_time = None
            
            # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å–å¾—
            baseline_row = query_results[query_results['strategy_name'] == 'no_index']
            if not baseline_row.empty:
                baseline_time = baseline_row.iloc[0]['execution_time_ms']
            
            fastest_time = query_results.iloc[0]['execution_time_ms']
            
            for _, row in query_results.iterrows():
                time_ms = row['execution_time_ms']
                improvement = ""
                emoji = ""
                
                if baseline_time and baseline_time > 0:
                    if row['strategy_name'] == 'no_index':
                        improvement = " (ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³)"
                        emoji = "ğŸ˜±"
                    else:
                        ratio = baseline_time / time_ms
                        if ratio > 10:
                            improvement = f" ({ratio:.0f}å€é«˜é€ŸåŒ–!!!)"
                            emoji = "ğŸš€"
                        elif ratio > 5:
                            improvement = f" ({ratio:.1f}å€é«˜é€ŸåŒ–!!)"
                            emoji = "âš¡"
                        elif ratio > 2:
                            improvement = f" ({ratio:.1f}å€é«˜é€ŸåŒ–!)"
                            emoji = "âœ¨"
                        elif ratio > 1.1:
                            improvement = f" ({ratio:.1f}å€é«˜é€ŸåŒ–)"
                            emoji = "ğŸ“ˆ"
                        else:
                            improvement = f" ({time_ms/baseline_time:.1f}å€ä½é€ŸåŒ–)"
                            emoji = "ğŸ’©"
                
                print(f"{emoji} {row['strategy_description']:40} {time_ms:8.1f}ms{improvement}")
        
        # JSONã§è©³ç´°ä¿å­˜
        with open('impact_results.json', 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“ è©³ç´°çµæœã‚’impact_results.jsonã«ä¿å­˜")
        print(f"ğŸ“Š ç·è¨ˆ {len(self.results)} ä»¶ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    benchmark = ImprovedBenchmark()
    
    try:
        # å…¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‰Šé™¤ã—ã¦ã‚¯ãƒªãƒ¼ãƒ³ã‚¹ã‚¿ãƒ¼ãƒˆ
        benchmark.drop_all_indexes()
        
        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
        benchmark.run_benchmark_suite()
        
        # ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        benchmark.generate_impact_report()
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"ğŸ’¥ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        try:
            benchmark.drop_all_indexes()
        except:
            pass

if __name__ == "__main__":
    main()
